% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tensor.R
\name{tensor_eigen}
\alias{tensor_eigen}
\title{Tensor Decomposition for LDA Model}
\usage{
tensor_eigen(X, a0, p, K, L, N)
}
\arguments{
\item{X}{A gene count matrix with gene names as row names and sample(bulk) names as column names. Single cell
data are not provided in this case.}

\item{a0}{A positive value. This is the sum of concentration parameter \code{alpha}.}

\item{K}{An integer. The length of \code{alpha}.}

\item{L}{A positive integer. The number of starting points to use in the algorithm.}

\item{N}{A positive integer. The number of iterations to use in the algorithm.}

\item{P}{An integer. The number of eigenvalues of M2 matrix to use in finding \code{alpha}. When
\code{P} is larger than the number of positive eigenvalues of M2, the algorithm will automatically choose the
largest number of positive eigenvalues of M2 as \code{P}.}
}
\value{
\code{tensor_eigen} returns a vector of the rates of the concentration parameter \code{alpha}.
}
\description{
Find the concentration parameter \code{alpha} of proportion matrix W.
}
\examples{
#generate a count matrix X(bulk counts) without single cell counts.
list1<-samplecounts(N=200,M1=150,Ks=0,Kb=3,Nm=5,Na=0,Nh=20,alpha=c(100,200,300),missing=0)
X<-list1$X
a<-tensor_eigen(X,a0=600,p=10,K=3,L=100,N=150)
a

}
\references{
Animashree Anandkumar, Rong Ge, Daniel Hsu, Sham M. Kakade, Matus Telgarsky,
\emph{Tensor Decompositions for Learning Latent Variable Models}. Journal of Machine Learning Research 15 (2014) ,
pages 2773-2832.
}
